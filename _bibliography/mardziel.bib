@string{acm  = "ACM"}
@string{ieee = "IEEE"}

% journals
@string{jcs = "Journal of Computer Security"}

% conferences
@string{csf = ieee # " Computer Security Foundations Symposium (CSF)"}
@string{sap = ieee # " Symposium on Security and Privacy (S&P)"} 

% workshops
@string{plas = acm # " SIGPLAN Workshop on Programming Languages and Analysis for Security (PLAS)"}
@string{fcs = "Workshop on Foundations of Computer Security (FCS)"}
@string{nipspp = "NIPS Workshop on Probabilistic Programming"}

% fake conferences
@string{acita = "Anual Conference of the International Technology Alliance (ACITA)"}

@string{inproc  = "Proceedings of the "}
@string{invited = "Invited paper, "}
@string{toappear = "To appear"}

@string{JAN = "January"}
@string{FEB = "February"}
@string{MAR = "March"}
@string{APR = "April"}
@string{MAY = "May"}
@string{JUN = "June"}
@string{JUL = "July"}
@string{AUG = "August"}
@string{SEP = "September"}
@string{OCT = "October"}
@string{NOV = "November"}
@string{DEC = "December"}

@string{break = "<p/>"}

project{knowledge,
  name = {Knowledge-based Security},
}

project{qif,
  names = {Quantified Information Flow},
}

project{smc,
  name = {Secure Multi-party Computation},
}

author{piotr,
 name = {Piotr Mardziel},
 link = {http://www.cs.umd.edu/~piotrm},
 is_member = 1,
 icon = {http://software.imdea.org/images/piotr.mardziel.png}
}

author{aseem,
 name = {Aseem Rastogi},
 link = {http://www.cs.umd.edu/~aseem},
 is_member = 1,
 icon = {http://www.cs.umd.edu/~aseem/pic.jpg},
}

author{matt,
 name = {Matthew Hammer},
 link = {http://www.mpi-sws.org/~hammer/},
 is_member = 1,
 icon = {http://www.mpi-sws.org/~hammer/me_rounded.png},
}

author{mike,
 name = {Michael Hicks},
 link = {http://www.cs.umd.edu/~mwh},
 is_member = 1,
 icon = {http://www.cs.umd.edu/~mwh/mike2011.jpg},
}

author{stephen-magill,
 name = {Stephen Magill},
 link = {http://www.cs.cmu.edu/~smagill},
 is_former = 1,
 is_member = 0,
 icon = {http://www.cs.cmu.edu/~smagill/common/portrait.gif},
 institution = {IDA/CCS},
}

author{mudhakar-srivatsa,
 name = {Mudhakar Srivatsa},
 link = {http://researcher.watson.ibm.com/researcher/view.php?person=us-msrivats},
 icon = {http://researcher.watson.ibm.com/researcher/photos/779.jpg},
 institution = {IBM Research},
}

author{jon-katz,
 name = {Jonathan Katz},
 link = {http://www.cs.umd.edu/~jkatz},
 icon = {http://www.cs.umd.edu/projects/photohistory/facultypictures_full/katz.jpg},
 institution = {UMD},
}

author{adam-bender,
 name = {Adam Bender},
 institution = {Google},
}

author{deve-levin,
 name = {Dave Levin},
 link = {http://www.cs.umd.edu/~dml},
 icon = {http://www.cs.umd.edu/~dml/dml_canossa.jpg},
 institution = {UMD},
}

author{mario-alvim,
 name = {Mario Alvim},
 link = {https://sites.google.com/site/msalvimjr/},
 icon = {https://sites.google.com/site/msalvimjr/_/rsrc/1380582081949/home/ms.jpg},
 institution = {UFMG},
}

author{michael-clarkson,
 name = {Michael R. Clarkson},
 link = {http://www.cs.cornell.edu/~clarkson/},
 icon = {http://www.cs.cornell.edu/~clarkson/img/mrc_slope300.jpg},
 institution = {GWU},
}

@INPROCEEDINGS{ruef15bibifi,
  TITLE = {Build It Break It: Measuring and Comparing Development Security},
  AUTHOR = {Andrew Ruef and Michael Hicks and James Parker and Dave Levin and Atif Memon and Jandelyn Plane and Piotr Mardziel},
  BOOKTITLE = {Proceedings of the USENIX Workshop on Cyber Security Instrumentation and Test (CSET)},
  MONTH = {AUG},
  YEAR = {2015},
  abstract = {There is currently little evidence about what tools,
                  methods, processes, and languages lead to secure
                  software. We present the experimental design of the
                  Build it Break it secure programming contest as an
                  aim to provide such evidence. The contest also
                  provides education value to participants where they
                  gain experience developing programs in an
                  adversarial settings. We show preliminary results
                  from previous runs of the contest that demonstrate
                  the contest works as designed, and provides the data
                  desired. We are in the process of scaling the
                  contest to collect larger data sets with the goal of
                  making statistically significant correlations
                  between various factors of development and software
                  security.}
}

@conference{khouzani15picking,
  title     = {Picking vs. Guessing Secrets: A Game-Theoretic Analysis},
  author    = {Khouzani, MHR and Mardziel, Piotr and Cid, Carlos and Srivatsa, Mudhakar},
  booktitle = inproc # csf,
  year      = {2015},
  month     = {JUL},
  abstract  = {Choosing a hard-to-guess secret is a prerequisite in
                  many security applications. Whether it is a password
                  for user authentication or a secret key for a
                  cryptographic primitive, picking it requires the
                  user to trade-off usability costs with resistance
                  against an adversary: a simple password is easier to
                  remember but is also easier to guess; likewise, a
                  shorter cryptographic key may require fewer
                  computational and storage resources but it is also
                  easier to attack. A fundamental question is how one
                  can optimally resolve this trade-off. A big
                  challenge is the fact that an adversary can also
                  utilize the knowledge of such usability vs. security
                  trade-offs to strengthen its attack. In this paper,
                  we propose a game-theoretic framework for analyzing
                  the optimal trade-offs in the face of strategic
                  adversaries. We consider two types of adversaries:
                  those limited in their number of tries, and those
                  that are ruled by the cost of making individual
                  guesses. For each type, we derive the
                  mutually-optimal decisions as Nash Equilibria, the
                  strategically pessimistic decisions as maximin, and
                  optimal commitments as Strong Stackelberg Equilibria
                  of the game. We establish that when the adversaries
                  are faced with a capped number of guesses, the
                  user's optimal trade-off is a uniform randomization
                  over a subset of the secret domain. On the other
                  hand, when the attacker strategy is ruled by the
                  cost of making individual guesses, Nash Equilibria
                  may completely fail to provide the user with any
                  level of security, signifying the crucial role of
                  credible commitment for such cases. We illustrate
                  our results using numerical examples based on
                  real-world samples and discuss some policy
                  implications of our work.}
}

@techreport{khouzani15pickingTR,
  title     = {Technical Report: Picking vs. Guessing Secrets: A Game-Theoretic Analysis},
  author    = {Khouzani, MHR and Mardziel, Piotr and Cid, Carlos and Srivatsa, Mudhakar},
  year      = {2015},
  month     = {MAY},
  note      = {Extended version includes proofs},
  archivePrefix = {arXiv},
  epring = {1505.02325},
  primaryClass = {cs},
  abstract  = {Choosing a hard-to-guess secret is a prerequisite in
                  many security applications. Whether it is a password
                  for user authentication or a secret key for a
                  cryptographic primitive, picking it requires the
                  user to trade-off usability costs with resistance
                  against an adversary: a simple password is easier to
                  remember but is also easier to guess; likewise, a
                  shorter cryptographic key may require fewer
                  computational and storage resources but it is also
                  easier to attack. A fundamental question is how one
                  can optimally resolve this trade-off. A big
                  challenge is the fact that an adversary can also
                  utilize the knowledge of such usability vs. security
                  trade-offs to strengthen its attack. In this paper,
                  we propose a game-theoretic framework for analyzing
                  the optimal trade-offs in the face of strategic
                  adversaries. We consider two types of adversaries:
                  those limited in their number of tries, and those
                  that are ruled by the cost of making individual
                  guesses. For each type, we derive the
                  mutually-optimal decisions as Nash Equilibria, the
                  strategically pessimistic decisions as maximin, and
                  optimal commitments as Strong Stackelberg Equilibria
                  of the game. We establish that when the adversaries
                  are faced with a capped number of guesses, the
                  user's optimal trade-off is a uniform randomization
                  over a subset of the secret domain. On the other
                  hand, when the attacker strategy is ruled by the
                  cost of making individual guesses, Nash Equilibria
                  may completely fail to provide the user with any
                  level of security, signifying the crucial role of
                  credible commitment for such cases. We illustrate
                  our results using numerical examples based on
                  real-world samples and discuss some policy
                  implications of our work.}
}

@phdthesis{mardziel15thesis,
  AUTHOR = {Piotr Mardziel},
  TITLE = {Modeling, Measuring, and Limiting Adversary Knowledge},
  YEAR = {2015},
  MONTH = {JAN},
  SCHOOL = {University of Maryland Department of Computer Science},
  ABSTRACT = {Users participating in online services are required to
                  relinquish control over potentially sensitive
                  personal information, exposing them to intentional
                  or unintentional miss-use of said information by the
                  service providers. Users wishing to avoid this must
                  either abstain from often extremely useful services,
                  or provide false information which is usually
                  contrary to the terms of service they must abide by.
                  An attractive middle-ground alternative is to
                  maintain control in the hands of the users and
                  provide a mechanism with which information that is
                  necessary for useful services can be queried. Users
                  need not trust any external party in the management
                  of their information but are now faced with the
                  problem of judging when queries by service providers
                  should be answered or when they should be refused
                  due to revealing too much sensitive information.<br/><br/>
                  
                  Judging query safety is difficult. Two queries may
                  be benign in isolation but might reveal more than a
                  user is comfortable with in combination.
                  Additionally malicious adversaries who wish to learn
                  more than allowed might query in a manner that
                  attempts to hide the flows of sensitive information.
                  Finally, users cannot rely on human inspection of
                  queries due to its volume and the general lack of
                  expertise.<br/><br/>

                  This thesis tackles the automation of query
                  judgment, giving the self-reliant user a means with
                  which to discern benign queries from dangerous or
                  exploitive ones. The approach is based on explicit
                  modeling and tracking of the knowledge of
                  adversaries as they learn about a user through the
                  queries they are allowed to observe. The approach
                  quantifies the absolute risk a user is exposed,
                  taking into account all the information that has
                  been revealed already when determining to answer a
                  query. Proposed techniques for approximate but sound
                  probabilistic inference are used to tackle the
                  tractability of the approach, letting the user
                  tradeoff utility (in terms of the queries judged
                  safe) and efficiency (in terms of the expense of
                  knowledge tracking), while maintaining the guarantee
                  that risk to the user is never underestimated. We
                  apply the approach to settings where user data
                  changes over time and settings where multiple users
                  wish to pool their data to perform useful
                  collaborative computations without revealing too
                  much information.<br/><br/>

                  By addressing one of the major
                  obstacles preventing the viability of personal
                  information control, this work brings the attractive
                  proposition closer to reality.}
}

@inproceedings{mardziel14loss,
  AUTHOR = {Piotr Mardziel and Mario Alvim and Michael Hicks},
  TITLE = {Adversary Gain vs. Defender Loss in Quantified Information Flow},
  BOOKTITLE = inproc # fcs,
  MONTH = JUL,
  YEAR = 2014,
  ABSTRACT = { Metrics for quantifying information leakage assume that
                  an adversary's gain is the defender's loss. We
                  demonstrate that this assumption does not always
                  hold via a class of scenarios. We describe how to
                  extend quantification to account for a defender with
                  goals distinct from adversary failure. We implement
                  the extension and experimentally explore the impact
                  on the measured information leakage of the
                  motivating scenario. },
}

@techreport{mardziel14timeTR,
  AUTHOR = {Piotr Mardziel and Mario Alvim and Michael Hicks and Michael R. Clarkson},
  TITLE = {Quantifying Information Flow for Dynamic Secrets},
  BOOKTITLE = inproc # sap,
  MONTH = MAY,
  YEAR = 2014,
  NUMBER = {CS-TR-5035},
  INSTITUTION = {University of Maryland Department of Computer Science},
  NOTE = {Extended version with proofs and memory limited adversary},
  ABSTRACT = {A metric is proposed for quantifying leakage of
                  information about secrets and about how secrets
                  change over time. The metric is used with a model of
                  information flow for probabilistic, interactive
                  systems with adaptive adversaries. The model and
                  metric are implemented in a probabilistic
                  programming language and used to analyze several
                  examples. The analysis demonstrates that adaptivity
                  increases information flow. }
}

@conference{mardziel14time,
  AUTHOR = {Piotr Mardziel and Mario Alvim and Michael Hicks and Michael R. Clarkson},
  TITLE = {Quantifying Information Flow for Dynamic Secrets},
  BOOKTITLE = inproc # sap,
  MONTH = MAY,
  YEAR = 2014,
  ABSTRACT = {A metric is proposed for quantifying leakage of
                  information about secrets and about how secrets
                  change over time. The metric is used with a model of
                  information flow for probabilistic, interactive
                  systems with adaptive adversaries. The model and
                  metric are implemented in a probabilistic
                  programming language and used to analyze several
                  examples. The analysis demonstrates that adaptivity
                  increases information flow. }
}

@misc{mardziel13acita,
  AUTHOR = {Piotr Mardziel and Michael Hicks and Jonathan Katz and Matthew Hammer and Aseem Rastogi and Mudhakar Srivatsa},
  TITLE = {Knowledge inference for optimizing and enforcing secure computations},
  BOOKTITLE = acita,
  NOTE = {This short paper consists of coherent excerpts from several prior papers},
  YEAR = 2013,
  MONTH = SEP,
  ABSTRACT = {We present several techniques that aim to compute the
                  belief or knowledge a party might have about the
                  values of hidden variables involved in the
                  computation. These techniques can be used for
                  enforcing knowledge-based security policies and for
                  optimizing secure multiparty computations.}
}

@inproceedings{rastogi13knowledge,
  AUTHOR = {Aseem Rastogi and Piotr Mardziel and Matthew Hammer and Michael Hicks},
  TITLE = {Knowledge Inference for Optimizing Secure Multi-party Computation},
  MONTH = JUN,
  YEAR = 2013,
  BOOKTITLE = plas,
  ABSTRACT = {In secure multi-party computation, mutually distrusting
                  parties cooperatively compute functions of their
                  private data; in the process, they only learn
                  certain results as per the protocol (e.g., the final
                  output). The realization of these protocols uses
                  cryptographic techniques to avoid leaking
                  information between the parties. A protocol for a
                  secure computation can sometimes be optimized
                  without changing its security guarantee: when the
                  parties can use their private data and the revealed
                  output to infer the values of other data, then this
                  other data need not be concealed from them via
                  cryptography. } # break # {In the context of
                  automatically optimizing secure multi-party
                  computation, we define two related problems,
                  knowledge inference and constructive knowledge
                  inference. In both problems, we attempt to
                  automatically discover when and if intermediate
                  variables used in a protocol will (eventually) be
                  known to the parties involved in the computation.
                  Provably-known variables offer optimization
                  opportunities.} # break # {We formally state the
                  problem of knowledge inference (and its constructive
                  variant); we describe our solutions, which are built
                  atop existing, standard technology such as SMT
                  solvers. We show that our approach is sound, and
                  further, we characterize the completeness properties
                  enjoyed by our approach. We have implemented our
                  approach, and present a preliminary experimental
                  evaluation. }
}

@ARTICLE{mardziel13dynamiclong,
  TITLE = {Dynamic Enforcement of Knowledge-based Security Policies using Probabilistic Abstract Interpretation},
  AUTHOR = {Piotr Mardziel and Stephen Magill and Michael Hicks and Mudhakar Srivatsa},
  YEAR = 2013,
  MONTH = JAN,
  JOURNAL = jcs,
  ABSTRACT = {This paper explores the idea of knowledge-based
                  security policies, which are used to decide whether
                  to answer queries over secret data based on an
                  estimation of the querier's (possibly increased)
                  knowledge given the results. Limiting knowledge is
                  the goal of existing information release policies
                  that employ mechanisms such as noising,
                  anonymization, and redaction. Knowledge-based
                  policies are more general: they increase flexibility
                  by not fixing the means to restrict information
                  flow. We enforce a knowledge-based policy by
                  explicitly tracking a model of a querier's belief
                  about secret data, represented as a probability
                  distribution, and denying any query that could
                  increase knowledge above a given threshold. We
                  implement query analysis and belief tracking via
                  abstract interpretation, which allows us to trade
                  off precision and performance through the use of
                  abstraction. We have developed an approach to
                  augment standard abstract domains to include
                  probabilities, and thus define distributions. We
                  focus on developing probabilistic polyhedra in
                  particular, to support numeric programs. While
                  probabilistic abstract interpretation has been
                  considered before, our domain is the first whose
                  design supports sound conditioning, which is
                  required to ensure that estimates of a querier's
                  knowledge are accurate. Experiments with our
                  implementation show that several useful queries can
                  be handled efficiently, particularly compared to
                  exact (i.e., sound) inference involving sampling. We
                  also show that, for our benchmarks, restricting
                  constraints to octagons or intervals, rather than
                  full polyhedra, can dramatically improve performance
                  while incurring little to no loss in precision.}
}

@misc{mardziel12probabilistic,
  TITLE = {Probabilistic Computation for Information Security},
  AUTHOR = {Piotr Mardziel and Kasturi Raghavan},
  BOOKTITLE = nipspp,
  MONTH = DEC,
  YEAR = 2012,
  ABSTRACT = {Probabilistic computation is a convenient means of
                  mechanically reasoning about a variety of
                  information security problems. At its core,
                  information security concerns itself with measuring
                  or limiting the knowledge an adversary might attain
                  from interacting with a protected system.
                  Probabilistic inference lets one compute this
                  knowledge explicitly as long as the interaction can
                  be described as a program in a suitable
                  probabilistic language that supports conditioning.
                  Security concerns, however, require soundness
                  guarantees on probabilistic inference which are
                  generally not present in machine learning
                  applications. We summarize some recent work on
                  probabilistic computing for information security and
                  highlight challenging aspects that still need to be
                  addressed.}
}

@INPROCEEDINGS{mardziel12smc,
  TITLE = {Knowledge-Oriented Secure Multiparty Computation},
  AUTHOR = {Piotr Mardziel and Michael Hicks and Jonathan Katz and Mudhakar Srivatsa},
  BOOKTITLE = inproc # plas,
  MONTH = JUN,
  YEAR = 2012,
  ABSTRACT = {Protocols for secure multiparty computation (SMC) allow
                  a set of mutually distrusting parties to compute a
                  function f of their private inputs while revealing
                  nothing about their inputs beyond what is implied by
                  the result. Depending on f, however, the result
                  itself may reveal more information than parties are
                  comfortable with. Almost all previous work on SMC
                  treats f as given. Left unanswered is the question
                  of how parties should decide whether it is ``safe''
                  for them to compute f in the first place. } # break
                  # {We propose here a way to apply belief tracking to
                  SMC in order to address exactly this question. In
                  our approach, each participating party is able to
                  reason about the increase in knowledge that other
                  parties could gain as a result of computing f, and
                  may choose not to participate (or participate only
                  partially) so as to restrict that gain in knowledge.
                  We develop two techniques-the belief set method and
                  the SMC belief tracking method-prove them sound, and
                  discuss their precision/performance tradeoffs using
                  a series of experiments. }
}

@TECHREPORT{mardziel11dynamicTR,
  TITLE = {Dynamic Enforcement of Knowledge-based Security Policies},
  AUTHOR = {Piotr Mardziel and Stephen Magill and Michael Hicks and Mudhakar Srivatsa},
  NUMBER = {CS-TR-4978},
  INSTITUTION = {University of Maryland Department of Computer Science},
  YEAR = 2011,
  MONTH = JUL,
  NOTE = {Extended version with proofs and additional benchmarks},
  ABSTRACT = {This paper explores the idea of knowledge-based security
                  policies, which are used to decide whether to answer
                  queries over secret data based on an estimation of
                  the querier's (possibly increased) knowledge given
                  the results. Limiting knowledge is the goal of
                  existing information release policies that employ
                  mechanisms such as noising, anonymization, and
                  redaction. Knowledge-based policies are more
                  general: they increase flexibility by not fixing the
                  means to restrict information flow. We enforce a
                  knowledge-based policy by explicitly tracking a
                  model of a querier's belief about secret data,
                  represented as a probability distribution, and
                  denying any query that could increase knowledge
                  above a given threshold. We implement query analysis
                  and belief tracking via abstract interpretation
                  using a novel probabilistic polyhedral domain, whose
                  design permits trading off precision with
                  performance while ensuring estimates of a querier's
                  knowledge are sound. Experiments with our
                  implementation show that several useful queries can
                  be handled efficiently, and performance scales far
                  better than would more standard implementations of
                  probabilistic computation based on sampling.}
}

@conference{mardziel11dynamic,
  TITLE = {Dynamic Enforcement of Knowledge-based Security Policies},
  AUTHOR = {Piotr Mardziel and Stephen Magill and Michael Hicks and Mudhakar Srivatsa},
  BOOKTITLE = inproc # csf,
  YEAR = 2011,
  MONTH = JUN,
  PAGES = {114--128},
  ABSTRACT = {This paper explores the idea of knowledge-based
                  security policies, which are used to decide whether
                  to answer queries over secret data based on an
                  estimation of the querier's (possibly increased)
                  knowledge given the results. Limiting knowledge is
                  the goal of existing information release policies
                  that employ mechanisms such as noising,
                  anonymization, and redaction. Knowledge-based
                  policies are more general: they increase flexibility
                  by not fixing the means to restrict information
                  flow. We enforce a knowledge-based policy by
                  explicitly tracking a model of a querier's belief
                  about secret data, represented as a probability
                  distribution, and denying any query that could
                  increase knowledge above a given threshold. We
                  implement query analysis and belief tracking via
                  abstract interpretation using a novel probabilistic
                  polyhedral domain, whose design permits trading off
                  precision with performance while ensuring estimates
                  of a querier's knowledge are sound. Experiments with
                  our implementation show that several useful queries
                  can be handled efficiently, and performance scales
                  far better than would more standard implementations
                  of probabilistic computation based on sampling.}
}

@misc{mardziel10acita,
  TITLE = {Secure sharing in distributed information management applications: problems and directions},
  AUTHOR = {Piotr Mardziel and Adam Bender and Michael Hicks and Dave Levin and Mudhakar Srivatsa and Jonathan Katz},
  BOOKTITLE = acita,
  MONTH = SEP,
  YEAR = 2010,
  ABSTRACT = {Interaction between entities who may not trust each
                  other is now commonplace on the Internet. This paper
                  focuses on the specific problem of sharing
                  information between distrusting parties. Previous
                  work in this area shows that privacy and utility can
                  co-exist, but often do not provide strong assurances
                  of one or the other. In this paper, we sketch a
                  research agenda with several directions for
                  attacking these problems, considering several
                  alternative systems that examine the privacy vs.
                  utility problem from different angles. We consider
                  new mechanisms such as economic incentives to share
                  data or discourage data leakage and a hybrid of
                  code-splitting and secure multi-party computation to
                  provide various assurances of secrecy. We discuss
                  how to incorporate these mechanisms into practical
                  applications, including online social networks, a
                  recommendation system based on users' qualifications
                  rather than identities, and a personal information
                  broker that monitors data leakage over time. We hope
                  that this paper will spark ideas and conversation at
                  ACITA about directions most worth pursuing. }
}
